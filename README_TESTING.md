# Testing Guide for Autocode Interfaces

Este documento proporciona una guÃ­a completa para ejecutar y entender los tests del mÃ³dulo `autocode/interfaces`. Los tests estÃ¡n diseÃ±ados siguiendo principios de buen cÃ³digo (SOLID, DRY, KISS) y pensando en la escalabilidad futura del proyecto.

## ğŸš€ EjecuciÃ³n RÃ¡pida

```bash
# Ejecutar todos los tests con coverage
pytest

# Ejecutar tests especÃ­ficos por mÃ³dulo
pytest tests/interfaces/test_models.py
pytest tests/interfaces/test_registry.py
pytest tests/interfaces/test_api.py
pytest tests/interfaces/test_cli.py
pytest tests/interfaces/test_mcp.py

# Ejecutar tests de integraciÃ³n
pytest tests/test_integration.py
```

## ğŸ“ Estructura de Tests

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conftest.py                    # Fixtures globales y configuraciÃ³n
â”œâ”€â”€ pytest.ini                    # ConfiguraciÃ³n de pytest
â”œâ”€â”€ interfaces/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_models.py            # Tests para Pydantic models
â”‚   â”œâ”€â”€ test_registry.py          # Tests para funciÃ³n registry
â”‚   â”œâ”€â”€ test_api.py               # Tests para FastAPI endpoints
â”‚   â”œâ”€â”€ test_cli.py               # Tests para CLI con Click
â”‚   â””â”€â”€ test_mcp.py               # Tests para integraciÃ³n MCP
â””â”€â”€ test_integration.py           # Tests de integraciÃ³n cross-module
```

### Principios de OrganizaciÃ³n

- **Mirroring Structure**: Los tests siguen la estructura del cÃ³digo fuente para facilitar la navegaciÃ³n
- **SeparaciÃ³n de Responsabilidades**: Unit tests vs integration tests claramente separados
- **Isolation**: Cada test es independiente gracias a fixtures de cleanup
- **Mocks Inteligentes**: Se usan mocks para dependencias externas, preservando la lÃ³gica interna

## ğŸ¯ Cobertura por MÃ³dulo

### `models.py` - Tests de ValidaciÃ³n de Datos
- **ExplicitParam**: ValidaciÃ³n de parÃ¡metros con types, defaults, required fields
- **FunctionInfo**: Metadata completa de funciones con arbitrary types
- **GenericOutput**: Responses estandarizadas con success/error handling
- **Edge Cases**: Valores invÃ¡lidos, None defaults, tipos complejos

**Principio aplicado**: *Single Responsibility* - cada model tiene una responsabilidad clara.

### `registry.py` - Tests del CorazÃ³n del Sistema
- **Function Registration**: Decorator automÃ¡tico con inferencia de parÃ¡metros
- **Parameter Inference**: ExtracciÃ³n de types desde signatures y docstrings
- **Public API**: `get_function`, `get_function_info`, `get_parameters`, etc.
- **Error Handling**: RegistryError para casos no encontrados
- **Stats & Metrics**: Registry statistics para monitoring

**Principio aplicado**: *Open/Closed* - extensible para nuevas funciones sin modificar cÃ³digo existente.

### `api.py` - Tests de Endpoints DinÃ¡micos
- **Dynamic Model Generation**: Pydantic models generados automÃ¡ticamente
- **Request/Response Handling**: Formateo consistente de responses
- **Error Management**: HTTP status codes apropiados (400/500)
- **Endpoint Registration**: GeneraciÃ³n automÃ¡tica de GET/POST routes
- **Integration**: TestClient para simulaciÃ³n de requests reales

**Principio aplicado**: *DRY* - generaciÃ³n automÃ¡tica elimina cÃ³digo repetitivo.

### `cli.py` - Tests de Interfaz de LÃ­nea de Comandos  
- **Dynamic Commands**: Comandos Click generados desde registry
- **Parameter Mapping**: Types Python â†’ Click types automÃ¡ticamente
- **Built-in Commands**: `list`, `serve-api`, `serve-mcp`, `serve`
- **Error Handling**: Graceful handling con Abort para user experience
- **Help System**: DocumentaciÃ³n automÃ¡tica desde docstrings

**Principio aplicado**: *Interface Segregation* - comandos especÃ­ficos para diferentes necesidades.

### `mcp.py` - Tests de IntegraciÃ³n MCP
- **MCP Server Creation**: FastApiMCP integration seamless
- **App Modification**: PreservaciÃ³n de funcionalidad API original
- **Error Propagation**: RuntimeError con chaining para debugging
- **Logging**: Comprehensive logging para monitoring

**Principio aplicado**: *Dependency Inversion* - MCP como abstraction layer.

### `test_integration.py` - Tests End-to-End
- **Cross-Module Integration**: Registry â†” API â†” CLI â†” MCP
- **Real-World Scenarios**: SimulaciÃ³n de code quality tools
- **Consistency Checks**: Mismo comportamiento across interfaces
- **Error Propagation**: Manejo de errores consistent entre mÃ³dulos

## ğŸ› ï¸ ConfiguraciÃ³n y Herramientas

### `pytest.ini` - ConfiguraciÃ³n Central
```ini
[tool:pytest]
testpaths = tests
addopts = 
    -v                              # Verbose output
    --tb=short                      # Short traceback format
    --cov=autocode                  # Coverage analysis
    --cov-report=term-missing       # Show missing lines
    --cov-report=html:htmlcov       # HTML report
    --cov-fail-under=80             # Minimum 80% coverage
```

### `conftest.py` - Fixtures Globales
- **cleanup_registry**: Auto-cleanup para isolation entre tests
- **sample_function/function_info**: Objetos reutilizables para testing
- **mock_uvicorn/fastapi_app**: Mocks para dependencias externas
- **populated_registry**: Registry con datos de test para integration
- **test clients**: FastAPI TestClient y Click CliRunner factories

## ğŸ“Š Comandos de Testing

### Comandos BÃ¡sicos
```bash
# Tests completos con coverage
pytest

# Tests especÃ­ficos por markers
pytest -m unit          # Solo unit tests
pytest -m integration   # Solo integration tests
pytest -m api          # Solo tests de API
pytest -m cli          # Solo tests de CLI

# Tests con output detallado
pytest -v -s

# Tests con coverage especÃ­fico
pytest --cov=autocode.autocode.interfaces --cov-report=term-missing
```

### Debugging y Desarrollo
```bash
# Ejecutar test especÃ­fico
pytest tests/interfaces/test_registry.py::TestGenerateFunctionInfo::test_generate_function_info_simple

# Tests con pdb debugger
pytest --pdb

# Tests paralelos (requiere pytest-xdist)
pytest -n auto

# Ver warnings completos
pytest --disable-warnings=false
```

### Coverage Analysis
```bash
# Generar reporte HTML
pytest --cov-report=html
open htmlcov/index.html

# Coverage con detalles por lÃ­nea
pytest --cov-report=term-missing

# Coverage solo para mÃ³dulos especÃ­ficos
pytest --cov=autocode.autocode.interfaces.registry --cov-report=term
```

## ğŸ¨ Principios de Testing Aplicados

### 1. **Test Early, Test Often** (Agile)
- Tests automatizados en cada commit
- DetecciÃ³n temprana de regressions
- CI/CD ready para deploys seguros

### 2. **SOLID Principles**
- **S**: Cada test verifica una responsabilidad especÃ­fica
- **O**: Tests extensibles sin modificar existentes
- **L**: Mocks sustituyen dependencias sin romper contracts
- **I**: Interfaces especÃ­ficas para diferentes tipos de tests
- **D**: Tests dependen de abstractions, no implementations

### 3. **DRY (Don't Repeat Yourself)**
- Fixtures reutilizables en `conftest.py`
- Parametrized tests para mÃºltiples scenarios
- Helper functions para setup comÃºn

### 4. **KISS (Keep It Simple, Stupid)**
- Tests legibles como documentaciÃ³n
- Setup mÃ­nimo necesario por test
- Asserts claros y especÃ­ficos

## ğŸš€ Beneficios para el Futuro

### Escalabilidad
- **Nuevas Funciones**: AÃ±adir functions al registry â†’ tests automÃ¡ticos
- **Nuevos Interfaces**: Pattern establecido para CLI/API/MCP extensions  
- **CI/CD Integration**: GitHub Actions ready para automatic testing

### Mantenibilidad  
- **Refactoring Seguro**: High coverage previene regressions
- **Documentation**: Tests como living documentation del sistema
- **Onboarding**: Nuevos developers entienden el sistema via tests

### Calidad
- **Edge Cases**: Coverage de error scenarios y boundary conditions
- **Integration**: Cross-module testing asegura cohesiÃ³n
- **Real-World**: Simulation de uso real (code quality tools)

## ğŸ¯ MÃ©tricas de Calidad

### Coverage Targets
- **Minimum**: 80% coverage (enforced by pytest.ini)
- **Target**: 90%+ para mÃ³dulos core (registry, api)
- **Integration**: 100% de paths crÃ­ticos cubiertos

### Test Categories
- **Unit Tests**: ~70% del total (fast, isolated)
- **Integration Tests**: ~25% del total (cross-module)
- **End-to-End**: ~5% del total (realistic scenarios)

### Performance
- **Fast Tests**: <1s para unit tests individuales
- **Full Suite**: <30s para test suite completo
- **Parallel Execution**: Support para pytest-xdist

## ğŸ“ Mejores PrÃ¡cticas

### Escribir Nuevos Tests
1. **Seguir Naming Convention**: `test_function_name_scenario`
2. **Usar Fixtures**: Aprovechar fixtures existentes en `conftest.py`
3. **Mock External Dependencies**: No hacer real HTTP calls, file I/O
4. **Test Both Paths**: Happy path y error scenarios
5. **Clear Assertions**: Asserts especÃ­ficos con mensajes claros

### Mantener Tests
1. **Update con Cambios**: Tests deben reflejar cambios en cÃ³digo
2. **Refactor Tests**: Eliminar duplicaciÃ³n, improve readability
3. **Monitor Coverage**: Aim for high coverage sin obsesiÃ³n
4. **Review Tests**: Tests tambiÃ©n necesitan code review

### Debugging Tests
1. **Use pytest -v**: Para output detallado
2. **Add print()**: Temporary debugging (remove afterwards)
3. **Use pdb**: `pytest --pdb` para interactive debugging
4. **Isolate Failing**: Run specific test para faster iteration

## ğŸ¤ Contribuciones

Al agregar nuevas funciones a `autocode/interfaces`:

1. **Add Unit Tests**: Para la funciÃ³n especÃ­fica
2. **Update Integration**: Si afecta cross-module behavior  
3. **Test Documentation**: Docstrings como parte del test
4. **Run Full Suite**: Asegurar no breaks en existing functionality
5. **Update Coverage**: Maintain o improve coverage metrics

Los tests estÃ¡n diseÃ±ados para **crecer con el proyecto**. Cada nueva funciÃ³n registrada automÃ¡ticamente obtiene tests de API y CLI, y la infraestructura soporta expansion a nuevos tipos de interfaces sin modification major.

## ğŸ“ Soporte

Para preguntas sobre testing:
1. **Revisar este documento** para patrones establecidos
2. **Examinar tests existentes** como ejemplos
3. **Usar fixtures globales** cuando sea posible
4. **Seguir principios SOLID** en test design

Los tests son **living documentation** - mantienen el cÃ³digo robusto y facilitan evoluciÃ³n segura del proyecto.
